{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d34d61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import skimage.io\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from keras.applications.nasnet import NASNetLarge\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cf67d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## multiply the images and expand the size of the dataset to have modified dataset \n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   validation_split = 0.2,\n",
    "                                  \n",
    "        rotation_range=5,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                  validation_split = 0.2)\n",
    "\n",
    "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7283d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset  = train_datagen.flow_from_directory(directory = 'dataset/train',\n",
    "                                                   target_size = (48,48),\n",
    "                                                   class_mode = 'categorical',\n",
    "                                                   subset = 'training',\n",
    "                                                   batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64776db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage import data, exposure\n",
    "\n",
    "\n",
    "image =train_data\n",
    "\n",
    "fd, hog_image = hog(image, orientations=8, pixels_per_cell=(32, 32),\n",
    "                    cells_per_block=(1, 1), visualize=True)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "\n",
    "ax1.axis('off')\n",
    "ax1.imshow(image, cmap=plt.cm.gray)\n",
    "ax1.set_title('Input image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70e0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca0f995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752e6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec51035a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c2b29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d18e964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5741 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_dataset = valid_datagen.flow_from_directory(directory = 'dataset/train',\n",
    "                                                  target_size = (48,48),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  subset = 'validation',\n",
    "                                                  batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c89fa60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## my dataset\n",
    "#test_dataset = test_datagen.flow_from_directory(directory = 'myDataset/test',\n",
    " #                                                 target_size = (48,48),\n",
    "  #                                                class_mode = 'categorical',\n",
    "   #                                               batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3eaa2724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "test_dataset = test_datagen.flow_from_directory(directory = 'dataset/test',\n",
    "                                                  target_size = (48,48),\n",
    "                                                  class_mode = 'categorical',\n",
    "                                                  batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83a95608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 48, 3)\n",
      "(1, 48, 48, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "img = image.load_img(\"dataset/test/angry/im2.png\",target_size=(48,48))\n",
    "img = np.array(img)\n",
    "plt.imshow(img)\n",
    "print(img.shape)\n",
    "\n",
    "img = np.expand_dims(img, axis=0)\n",
    "from keras.models import load_model\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7010fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
      "16711680/16705208 [==============================] - 5s 0us/step\n"
     ]
    }
   ],
   "source": [
    "## scale width/depth/resolution \n",
    "## used here so i can load the weight from imagent \n",
    "#imagenet is using to classify million of trainded images and compare them with each other \n",
    "base_model = tf.keras.applications.EfficientNetB0(input_shape=(48,48,3),include_top=False,weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6d4b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing Layers so the weight not be modifyed \n",
    "\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "264eee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Model\n",
    "\n",
    "model=Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32,kernel_initializer='he_uniform'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(7,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7dee0137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb0 (Functional)  (None, 2, 2, 1280)        4049571   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2, 2, 1280)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 5120)              20480     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                163872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 4,236,650\n",
      "Trainable params: 589,447\n",
      "Non-trainable params: 3,647,203\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1df5d2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score(y_true, y_pred): #taken from old keras source code\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "807716ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      tf.keras.metrics.Precision(name='precision'),\n",
    "      tf.keras.metrics.Recall(name='recall'),  \n",
    "      tf.keras.metrics.AUC(name='auc'),\n",
    "        f1_score,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c30a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\n",
    "\n",
    "mcp = ModelCheckpoint('Mymodel.h5')\n",
    "\n",
    "es = EarlyStopping(verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04381d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f773b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "359/359 [==============================] - 1271s 4s/step - loss: 1.9108 - accuracy: 0.8549 - precision: 0.2239 - recall: 0.0064 - auc: 0.6118 - f1_score: 0.0120 - val_loss: 1.8162 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6438 - val_f1_score: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\utils\\generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50\n",
      "359/359 [==============================] - 96s 269ms/step - loss: 1.8374 - accuracy: 0.8570 - precision: 0.2200 - recall: 4.7893e-04 - auc: 0.6321 - f1_score: 9.3760e-04 - val_loss: 1.8101 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6429 - val_f1_score: 0.0000e+00\n",
      "Epoch 3/50\n",
      "359/359 [==============================] - 99s 276ms/step - loss: 1.8265 - accuracy: 0.8571 - precision: 0.2500 - recall: 4.3539e-05 - auc: 0.6355 - f1_score: 8.5708e-05 - val_loss: 1.8100 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6432 - val_f1_score: 0.0000e+00\n",
      "Epoch 4/50\n",
      "359/359 [==============================] - 100s 279ms/step - loss: 1.8242 - accuracy: 0.8572 - precision: 0.6667 - recall: 8.7078e-05 - auc: 0.6362 - f1_score: 1.7142e-04 - val_loss: 1.8101 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6442 - val_f1_score: 0.0000e+00\n",
      "Epoch 5/50\n",
      "359/359 [==============================] - 99s 277ms/step - loss: 1.8207 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6370 - f1_score: 0.0000e+00 - val_loss: 1.8098 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_f1_score: 0.0000e+00\n",
      "Epoch 6/50\n",
      "359/359 [==============================] - 101s 281ms/step - loss: 1.8183 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6398 - f1_score: 0.0000e+00 - val_loss: 1.8103 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6434 - val_f1_score: 0.0000e+00\n",
      "Epoch 7/50\n",
      "359/359 [==============================] - 106s 296ms/step - loss: 1.8167 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6397 - f1_score: 0.0000e+00 - val_loss: 1.8105 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6439 - val_f1_score: 0.0000e+00\n",
      "Epoch 8/50\n",
      "359/359 [==============================] - 102s 286ms/step - loss: 1.8169 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6401 - f1_score: 0.0000e+00 - val_loss: 1.8100 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6443 - val_f1_score: 0.0000e+00\n",
      "Epoch 9/50\n",
      "359/359 [==============================] - 104s 290ms/step - loss: 1.8147 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6411 - f1_score: 0.0000e+00 - val_loss: 1.8101 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6436 - val_f1_score: 0.0000e+00\n",
      "Epoch 10/50\n",
      "359/359 [==============================] - 105s 292ms/step - loss: 1.8145 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6416 - f1_score: 0.0000e+00 - val_loss: 1.8097 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6443 - val_f1_score: 0.0000e+00\n",
      "Epoch 11/50\n",
      "359/359 [==============================] - 102s 283ms/step - loss: 1.8138 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6415 - f1_score: 0.0000e+00 - val_loss: 1.8096 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_f1_score: 0.0000e+00\n",
      "Epoch 12/50\n",
      "359/359 [==============================] - 103s 287ms/step - loss: 1.8137 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6424 - f1_score: 0.0000e+00 - val_loss: 1.8097 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6437 - val_f1_score: 0.0000e+00\n",
      "Epoch 13/50\n",
      "359/359 [==============================] - 102s 284ms/step - loss: 1.8134 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6417 - f1_score: 0.0000e+00 - val_loss: 1.8100 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6424 - val_f1_score: 0.0000e+00\n",
      "Epoch 14/50\n",
      "359/359 [==============================] - 102s 283ms/step - loss: 1.8124 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6426 - f1_score: 0.0000e+00 - val_loss: 1.8097 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6434 - val_f1_score: 0.0000e+00\n",
      "Epoch 15/50\n",
      "359/359 [==============================] - 101s 282ms/step - loss: 1.8126 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6422 - f1_score: 0.0000e+00 - val_loss: 1.8099 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6437 - val_f1_score: 0.0000e+00\n",
      "Epoch 16/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8125 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6425 - f1_score: 0.0000e+00 - val_loss: 1.8100 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6438 - val_f1_score: 0.0000e+00\n",
      "Epoch 17/50\n",
      "359/359 [==============================] - 101s 281ms/step - loss: 1.8115 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6436 - f1_score: 0.0000e+00 - val_loss: 1.8099 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_f1_score: 0.0000e+00\n",
      "Epoch 18/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8121 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6432 - f1_score: 0.0000e+00 - val_loss: 1.8099 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6431 - val_f1_score: 0.0000e+00\n",
      "Epoch 19/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8126 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6428 - f1_score: 0.0000e+00 - val_loss: 1.8097 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_f1_score: 0.0000e+00\n",
      "Epoch 20/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8114 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6431 - f1_score: 0.0000e+00 - val_loss: 1.8102 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6432 - val_f1_score: 0.0000e+00\n",
      "Epoch 21/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8123 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6423 - f1_score: 0.0000e+00 - val_loss: 1.8098 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6438 - val_f1_score: 0.0000e+00\n",
      "Epoch 22/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8120 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6426 - f1_score: 0.0000e+00 - val_loss: 1.8096 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_f1_score: 0.0000e+00\n",
      "Epoch 23/50\n",
      "359/359 [==============================] - 100s 279ms/step - loss: 1.8108 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6437 - f1_score: 0.0000e+00 - val_loss: 1.8099 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_f1_score: 0.0000e+00\n",
      "Epoch 24/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8115 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6425 - f1_score: 0.0000e+00 - val_loss: 1.8100 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6431 - val_f1_score: 0.0000e+00\n",
      "Epoch 25/50\n",
      "359/359 [==============================] - 101s 280ms/step - loss: 1.8112 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6435 - f1_score: 0.0000e+00 - val_loss: 1.8103 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6438 - val_f1_score: 0.0000e+00\n",
      "Epoch 26/50\n",
      "359/359 [==============================] - 100s 279ms/step - loss: 1.8117 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6424 - f1_score: 0.0000e+00 - val_loss: 1.8098 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6430 - val_f1_score: 0.0000e+00\n",
      "Epoch 27/50\n",
      "359/359 [==============================] - 19118s 53s/step - loss: 1.8112 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6425 - f1_score: 0.0000e+00 - val_loss: 1.8099 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6432 - val_f1_score: 0.0000e+00\n",
      "Epoch 28/50\n",
      "359/359 [==============================] - 7323s 20s/step - loss: 1.8112 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6427 - f1_score: 0.0000e+00 - val_loss: 1.8098 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6438 - val_f1_score: 0.0000e+00\n",
      "Epoch 29/50\n",
      "359/359 [==============================] - 1132s 3s/step - loss: 1.8118 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6425 - f1_score: 0.0000e+00 - val_loss: 1.8097 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6438 - val_f1_score: 0.0000e+00\n",
      "Epoch 30/50\n",
      "359/359 [==============================] - 122s 338ms/step - loss: 1.8106 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6427 - f1_score: 0.0000e+00 - val_loss: 1.8099 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6435 - val_f1_score: 0.0000e+00\n",
      "\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 31/50\n",
      "359/359 [==============================] - 116s 322ms/step - loss: 1.8110 - accuracy: 0.8571 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6428 - f1_score: 0.0000e+00 - val_loss: 1.8096 - val_accuracy: 0.8571 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6434 - val_f1_score: 0.0000e+00\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(train_dataset,validation_data=valid_dataset,epochs = 50,verbose = 1,callbacks=[lrd,mcp,es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02f3a3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\env_Sid\\lib\\site-packages\\ipykernel_launcher.py:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<HDF5 file \"Mymodel.h5\" (mode r+)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## creating my model\n",
    "#import h5py\n",
    "#h5py.File('Mymodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60aa62cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
